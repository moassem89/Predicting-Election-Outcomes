{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random as r\nfrom datetime import datetime\nfrom scipy import stats","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/update/president_polls_general_election.csv')","execution_count":3,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (6,22,25,29) have mixed types.Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"Index(['question_id', 'poll_id', 'cycle', 'state', 'pollster_id', 'pollster',\n       'sponsor_ids', 'sponsors', 'display_name', 'pollster_rating_id',\n       'pollster_rating_name', 'fte_grade', 'sample_size', 'population',\n       'population_full', 'methodology', 'office_type', 'seat_number',\n       'seat_name', 'start_date', 'end_date', 'election_date',\n       'sponsor_candidate', 'internal', 'partisan', 'tracking',\n       'nationwide_batch', 'ranked_choice_reallocated', 'created_at', 'notes',\n       'url', 'stage', 'race_id', 'answer', 'candidate_id', 'candidate_name',\n       'candidate_party', 'pct'],\n      dtype='object')"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"We keep only the columns that matter to our purposes here"},{"metadata":{"trusted":true},"cell_type":"code","source":"col_interest = ['state', 'pollster','fte_grade', 'sample_size','start_date', 'end_date',\n       'answer', 'pct']","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_interest = data[col_interest]","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_interest.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"          state                             pollster fte_grade  sample_size  \\\n0          Iowa                Public Policy Polling         B        871.0   \n1          Iowa                Public Policy Polling         B        871.0   \n2  Pennsylvania  Susquehanna Polling & Research Inc.         C        499.0   \n3  Pennsylvania  Susquehanna Polling & Research Inc.         C        499.0   \n4  Pennsylvania  Susquehanna Polling & Research Inc.         C        499.0   \n\n  start_date end_date     answer   pct  \n0    11/1/20  11/2/20      Biden  49.0  \n1    11/1/20  11/2/20      Trump  48.0  \n2    11/1/20  11/2/20      Biden  48.4  \n3    11/1/20  11/2/20      Trump  49.2  \n4    11/1/20  11/2/20  Jorgensen   1.4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>pollster</th>\n      <th>fte_grade</th>\n      <th>sample_size</th>\n      <th>start_date</th>\n      <th>end_date</th>\n      <th>answer</th>\n      <th>pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Iowa</td>\n      <td>Public Policy Polling</td>\n      <td>B</td>\n      <td>871.0</td>\n      <td>11/1/20</td>\n      <td>11/2/20</td>\n      <td>Biden</td>\n      <td>49.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Iowa</td>\n      <td>Public Policy Polling</td>\n      <td>B</td>\n      <td>871.0</td>\n      <td>11/1/20</td>\n      <td>11/2/20</td>\n      <td>Trump</td>\n      <td>48.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pennsylvania</td>\n      <td>Susquehanna Polling &amp; Research Inc.</td>\n      <td>C</td>\n      <td>499.0</td>\n      <td>11/1/20</td>\n      <td>11/2/20</td>\n      <td>Biden</td>\n      <td>48.4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Pennsylvania</td>\n      <td>Susquehanna Polling &amp; Research Inc.</td>\n      <td>C</td>\n      <td>499.0</td>\n      <td>11/1/20</td>\n      <td>11/2/20</td>\n      <td>Trump</td>\n      <td>49.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Pennsylvania</td>\n      <td>Susquehanna Polling &amp; Research Inc.</td>\n      <td>C</td>\n      <td>499.0</td>\n      <td>11/1/20</td>\n      <td>11/2/20</td>\n      <td>Jorgensen</td>\n      <td>1.4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Let's see which states districts we have, and check is anything is missing"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data_interest['state'].unique())","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"56"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_interest['state'].unique()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"array(['Iowa', 'Pennsylvania', 'Florida', nan, 'Nebraska CD-2', 'Montana',\n       'Maine', 'Maine CD-2', 'Maine CD-1', 'Arizona', 'North Carolina',\n       'Texas', 'Georgia', 'Illinois', 'Michigan', 'Minnesota',\n       'New Jersey', 'New York', 'Ohio', 'Wisconsin', 'Colorado',\n       'California', 'Virginia', 'Alabama', 'Nevada', 'Kansas',\n       'South Carolina', 'Mississippi', 'Indiana', 'Connecticut',\n       'Kentucky', 'Louisiana', 'Maryland', 'Missouri', 'Oregon',\n       'Tennessee', 'Washington', 'Wyoming', 'West Virginia', 'Vermont',\n       'Utah', 'South Dakota', 'Rhode Island', 'Oklahoma', 'New Mexico',\n       'New Hampshire', 'Nebraska', 'North Dakota', 'Massachusetts',\n       'Idaho', 'Hawaii', 'Delaware', 'District of Columbia', 'Arkansas',\n       'Alaska', 'Nebraska CD-1'], dtype=object)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"51 + a nan (missing) + the districts of Maine and Nebraska"},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at the names of those who ran for the U.S. presidency"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_interest['answer'].unique()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"array(['Biden', 'Trump', 'Jorgensen', 'Hawkins', 'West', 'Blankenship',\n       'De La Fuente', 'Simmons', 'Pierce', 'Pence', 'Harris', 'La Riva',\n       'Kennedy', 'Hornberger', 'Cuomo', 'Clinton', 'Obama', 'Amash',\n       'Sanders', 'Warren', 'Bloomberg', 'Buttigieg', 'Klobuchar',\n       'Gabbard', 'Steyer', 'Yang', 'Booker', 'Castro', \"O'Rourke\",\n       'Haley', 'Bullock', 'Delaney', 'Gillibrand', 'Williamson',\n       'Messam', 'Bennet', 'de Blasio', 'Winfrey', 'Inslee',\n       'Hickenlooper', 'Gravel', 'Moulton', 'Rapinoe', 'Swalwell', 'Ryan',\n       'Schultz', 'Brown', 'Pelosi', 'Schumer', 'Ocasio-Cortez'],\n      dtype=object)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"So many names. We will just focus on Biden and Trump"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_interest.info()","execution_count":11,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 16438 entries, 0 to 16437\nData columns (total 8 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   state        11385 non-null  object \n 1   pollster     16438 non-null  object \n 2   fte_grade    15253 non-null  object \n 3   sample_size  16436 non-null  float64\n 4   start_date   16438 non-null  object \n 5   end_date     16438 non-null  object \n 6   answer       16438 non-null  object \n 7   pct          16438 non-null  float64\ndtypes: float64(2), object(6)\nmemory usage: 1.0+ MB\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"We want to make dates into date format, not just an object string"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_interest['end_date'] = pd.to_datetime(data_interest['end_date'])\ndata_interest['start_date'] = pd.to_datetime(data_interest['start_date'])","execution_count":6,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_interest['end_date'] - data_interest['start_date']","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"0       1 days\n1       1 days\n2       1 days\n3       1 days\n4       1 days\n         ...  \n16433   1 days\n16434   1 days\n16435   1 days\n16436   1 days\n16437   1 days\nLength: 16438, dtype: timedelta64[ns]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Let's assume they are all for 1 day, so only one date of them matters, let's keep the end date"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_interest = data_interest.drop(columns = ['start_date'])","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_interest['end_date'].min()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"Timestamp('2018-11-13 00:00:00')"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"As early as Nov 2018! We will consider the polls from Oct 12, 2020, until Nov 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"period = pd.date_range(start='7/15/2020', end='11/2/2020')\ndata_period = data_interest[data_interest['end_date'].isin(period)]","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_period['end_date'].max()-data_period['end_date'].min()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"Timedelta('110 days 00:00:00')"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Let's make sure that period didn't exclude some states"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data_period['state'].unique())","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"56"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Drop rows with empty values, particularly will get rid of state nans"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_period = data_period.dropna()","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Run this if want to ignore congressional districts"},{"metadata":{},"cell_type":"markdown","source":"data_period = data_period.replace('Nebraska CD-1', 'Nebraska')\ndata_period = data_period.replace('Nebraska CD-2', 'Nebraska')\ndata_period = data_period.replace('Maine CD-1', 'Maine')\ndata_period = data_period.replace('Maine CD-2', 'Maine')"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data_period['state'].unique())","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"55"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's look at pollster grades in common\n\ndata_period['fte_grade'].unique()","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"array(['B', 'C', 'B-', 'C-', 'D-', 'C+', 'B/C', 'A+', 'B+', 'A-', 'A/B',\n       'C/D', 'A'], dtype=object)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"In what follows, we build two functions that give weights to pollsters, and to dates. Bigger weights for best pollsters and recent dates.\n\nBefore we proceed, we want to clarify to the reader how the data looks like."},{"metadata":{"trusted":true},"cell_type":"code","source":"def poll_best(state, date, candidate): \n#returns a table of data at best pollster grade at the date input for the candidate input\n    B = data_period[data_period['answer'] == candidate].drop(columns=['answer'])\n    for rating in ['A+', 'A', 'A-','A/B', 'B+', 'B', 'B-', 'B/C', 'C+', 'C', 'C-', 'C/D',\n        'D-']: # we ordered them\n        if state in B[B['fte_grade'] == rating].state.unique():\n            B_rating = B[B['fte_grade'] == rating]\n            B_rating_state = B_rating[B_rating['state'] == state]\n            return B_rating_state[B_rating_state['end_date'] == date]\n            break","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for date in period:\n    if len(poll_best('Florida', date,'Biden'))!=0:\n        display(poll_best('Florida', date,'Biden'))","execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"        state        pollster fte_grade  sample_size   end_date   pct\n8547  Florida  Marist College        A+       1047.0 2020-09-06  47.0\n8549  Florida  Marist College        A+        766.0 2020-09-06  48.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>pollster</th>\n      <th>fte_grade</th>\n      <th>sample_size</th>\n      <th>end_date</th>\n      <th>pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8547</th>\n      <td>Florida</td>\n      <td>Marist College</td>\n      <td>A+</td>\n      <td>1047.0</td>\n      <td>2020-09-06</td>\n      <td>47.0</td>\n    </tr>\n    <tr>\n      <th>8549</th>\n      <td>Florida</td>\n      <td>Marist College</td>\n      <td>A+</td>\n      <td>766.0</td>\n      <td>2020-09-06</td>\n      <td>48.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"        state             pollster fte_grade  sample_size   end_date   pct\n8218  Florida  Monmouth University        A+        428.0 2020-09-13  50.0\n8222  Florida  Monmouth University        A+        428.0 2020-09-13  50.0\n8224  Florida  Monmouth University        A+        428.0 2020-09-13  49.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>pollster</th>\n      <th>fte_grade</th>\n      <th>sample_size</th>\n      <th>end_date</th>\n      <th>pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8218</th>\n      <td>Florida</td>\n      <td>Monmouth University</td>\n      <td>A+</td>\n      <td>428.0</td>\n      <td>2020-09-13</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>8222</th>\n      <td>Florida</td>\n      <td>Monmouth University</td>\n      <td>A+</td>\n      <td>428.0</td>\n      <td>2020-09-13</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>8224</th>\n      <td>Florida</td>\n      <td>Monmouth University</td>\n      <td>A+</td>\n      <td>428.0</td>\n      <td>2020-09-13</td>\n      <td>49.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"        state                      pollster fte_grade  sample_size   end_date  \\\n7877  Florida  ABC News/The Washington Post        A+        765.0 2020-09-20   \n7879  Florida  ABC News/The Washington Post        A+        613.0 2020-09-20   \n\n       pct  \n7877  48.0  \n7879  47.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>pollster</th>\n      <th>fte_grade</th>\n      <th>sample_size</th>\n      <th>end_date</th>\n      <th>pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7877</th>\n      <td>Florida</td>\n      <td>ABC News/The Washington Post</td>\n      <td>A+</td>\n      <td>765.0</td>\n      <td>2020-09-20</td>\n      <td>48.0</td>\n    </tr>\n    <tr>\n      <th>7879</th>\n      <td>Florida</td>\n      <td>ABC News/The Washington Post</td>\n      <td>A+</td>\n      <td>613.0</td>\n      <td>2020-09-20</td>\n      <td>47.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"        state                                 pollster fte_grade  sample_size  \\\n6987  Florida  Siena College/The New York Times Upshot        A+        710.0   \n\n       end_date   pct  \n6987 2020-10-01  47.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>pollster</th>\n      <th>fte_grade</th>\n      <th>sample_size</th>\n      <th>end_date</th>\n      <th>pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6987</th>\n      <td>Florida</td>\n      <td>Siena College/The New York Times Upshot</td>\n      <td>A+</td>\n      <td>710.0</td>\n      <td>2020-10-01</td>\n      <td>47.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"        state        pollster fte_grade  sample_size   end_date   pct\n1849  Florida  Marist College        A+        743.0 2020-10-27  51.0\n1851  Florida  Marist College        A+       1001.0 2020-10-27  51.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>pollster</th>\n      <th>fte_grade</th>\n      <th>sample_size</th>\n      <th>end_date</th>\n      <th>pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1849</th>\n      <td>Florida</td>\n      <td>Marist College</td>\n      <td>A+</td>\n      <td>743.0</td>\n      <td>2020-10-27</td>\n      <td>51.0</td>\n    </tr>\n    <tr>\n      <th>1851</th>\n      <td>Florida</td>\n      <td>Marist College</td>\n      <td>A+</td>\n      <td>1001.0</td>\n      <td>2020-10-27</td>\n      <td>51.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"        state             pollster fte_grade  sample_size   end_date   pct\n1586  Florida  Monmouth University        A+        509.0 2020-10-28  50.0\n1590  Florida  Monmouth University        A+        509.0 2020-10-28  51.0\n1593  Florida  Monmouth University        A+        509.0 2020-10-28  50.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>pollster</th>\n      <th>fte_grade</th>\n      <th>sample_size</th>\n      <th>end_date</th>\n      <th>pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1586</th>\n      <td>Florida</td>\n      <td>Monmouth University</td>\n      <td>A+</td>\n      <td>509.0</td>\n      <td>2020-10-28</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>1590</th>\n      <td>Florida</td>\n      <td>Monmouth University</td>\n      <td>A+</td>\n      <td>509.0</td>\n      <td>2020-10-28</td>\n      <td>51.0</td>\n    </tr>\n    <tr>\n      <th>1593</th>\n      <td>Florida</td>\n      <td>Monmouth University</td>\n      <td>A+</td>\n      <td>509.0</td>\n      <td>2020-10-28</td>\n      <td>50.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"        state                      pollster fte_grade  sample_size   end_date  \\\n1281  Florida  ABC News/The Washington Post        A+        915.0 2020-10-29   \n1285  Florida  ABC News/The Washington Post        A+        824.0 2020-10-29   \n\n       pct  \n1281  47.0  \n1285  48.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>pollster</th>\n      <th>fte_grade</th>\n      <th>sample_size</th>\n      <th>end_date</th>\n      <th>pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1281</th>\n      <td>Florida</td>\n      <td>ABC News/The Washington Post</td>\n      <td>A+</td>\n      <td>915.0</td>\n      <td>2020-10-29</td>\n      <td>47.0</td>\n    </tr>\n    <tr>\n      <th>1285</th>\n      <td>Florida</td>\n      <td>ABC News/The Washington Post</td>\n      <td>A+</td>\n      <td>824.0</td>\n      <td>2020-10-29</td>\n      <td>48.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"       state                                 pollster fte_grade  sample_size  \\\n656  Florida  Siena College/The New York Times Upshot        A+       1451.0   \n\n      end_date   pct  \n656 2020-10-31  47.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>pollster</th>\n      <th>fte_grade</th>\n      <th>sample_size</th>\n      <th>end_date</th>\n      <th>pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>656</th>\n      <td>Florida</td>\n      <td>Siena College/The New York Times Upshot</td>\n      <td>A+</td>\n      <td>1451.0</td>\n      <td>2020-10-31</td>\n      <td>47.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The table above shows the highest grade polls for Florida over the period of time. You can see how for the same pollster, same method, and at the same time, we do sometimes have multiple values for the percentage and the sample size. Hence, we are taking average by weighting each percentage with the size of the corresponding sample and according to the dates as will be made clear below. In essence,\n$$\\frac{weight^Tpct}{\\sum weight}$$"},{"metadata":{},"cell_type":"markdown","source":"Now we proceed to our data assimilation funtions. First, it will be easier if we replace grade symbols by numerical values. Also this will help defining the functions in a way that works vectorially"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_period = data_period.replace('A+', 0)\ndata_period = data_period.replace('A', 1)\ndata_period = data_period.replace('A-', 2)\ndata_period = data_period.replace('A/B', 3)\ndata_period = data_period.replace('B+', 4)\ndata_period = data_period.replace('B', 5)\ndata_period = data_period.replace('B-', 6)\ndata_period = data_period.replace('B/C', 7)\ndata_period = data_period.replace('C+', 8)\ndata_period = data_period.replace('C', 9)\ndata_period = data_period.replace('C-', 10)\ndata_period = data_period.replace('C/D', 11)\ndata_period = data_period.replace('D-', 12)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def w_poll(grade):\n    return 1 - grade/15  # just a suitable denominator as grades take numbers up to 12\n\n# similarly for the dates\nend_p = period.max()\nd_date = 4+len(period)\ndef w_date(date):\n    return 1 - (end_p - date).dt.days/ d_date\n\n# Remark: we defined the variable end_p, d_date to make the code run faster and avoid computations within funcitons","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In what follows, we build a function which when given a state and condidate, it returns a percentage based on a weighted average over the pollsters and previous dates within the time period according."},{"metadata":{"trusted":true},"cell_type":"code","source":"def Assimilate1(state, candidate):\n    # look at the following subtable\n    C = data_period[data_period['answer'] == candidate]\n    C = C[C['state'] == state]\n    wd = w_date(C['end_date']) # weights of dates\n    wg = w_poll(C['fte_grade']) # wights of grades\n    wt = np.multiply(C['sample_size'], np.multiply(wd,wg)) # total weight\n    return np.sum(C['sample_size']), np.dot(C['pct'],wt)/np.sum(wt)\n# we return total sample size to use it when bootstrapping","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Assimilate1('Florida','Biden')","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"(701592.0, 49.224292359706354)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Actually, the following alternative is more helpful"},{"metadata":{"trusted":true},"cell_type":"code","source":"def Assimilate2(state):\n    # look at the following subtable\n    C = data_period[data_period['state'] == state]\n    CB = C[C['answer'] == 'Biden']\n    wd = w_date(CB['end_date']) # weights of dates\n    wg = w_poll(CB['fte_grade']) # wights of grades\n    wt = np.multiply(CB['sample_size'], np.multiply(wd,wg)) # total weight\n    pB = 0.01*np.dot(CB['pct'],wt)/np.sum(wt)\n    \n    CT = C[C['answer'] == 'Trump']\n    pT = 0.01*np.dot(CT['pct'],wt)/np.sum(wt)\n    \n    return np.sum(CB['sample_size']), pB,pT, 1-pT-pB\n# we return total sample size to use it when bootstrapping","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Assimilate2('Florida')","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"(701592.0, 0.4922429235970635, 0.4765304785633113, 0.03122659783962517)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Gorgeous!"},{"metadata":{},"cell_type":"markdown","source":"Now let's build a function that runs simulations and predicts Biden win probability using MC method"},{"metadata":{"trusted":true},"cell_type":"code","source":"def Return_prob_Biden(num_sim, state):\n    #num_sim is number of scenarios\n    #percs is the vector of probabilities 0: p_Biden 0, 1: p_Trump, 2:p_Other based on the assimilated percentages\n    sample_size,p0,p1,p2 = Assimilate2(state)\n    sz = int(sample_size)\n    sim_polls = np.random.choice([0,1,2], (num_sim, sz),[p0,p1,p2])\n    return np.mean(np.sum(sim_polls == np.zeros((num_sim, sz)),axis = 1)> \n                   np.sum(sim_polls == np.ones((num_sim, sz)),axis = 1))","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%timeit\nReturn_prob_Biden(1000, 'Florida')","execution_count":41,"outputs":[{"output_type":"stream","text":"18.1 s ± 94.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"This takes forever, maybe we should abandon some grades? Another thing to think about, does that weighting process affect big states? This can happen if there is a big state for which the only available pollsters have low grade, hence low weight. Let's take a look which states are available when we consider only top quality pollsters."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_period[data_period['fte_grade'] < 5].state.unique() # states getting weights above 0.7","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"array(['Arizona', 'Pennsylvania', 'Ohio', 'Florida', 'Michigan', 'Iowa',\n       'Nevada', 'Maine', 'Maine CD-1', 'Maine CD-2', 'North Carolina',\n       'Georgia', 'Texas', 'Wisconsin', 'Nebraska CD-2', 'Massachusetts',\n       'New Mexico', 'Minnesota', 'New Hampshire', 'South Dakota',\n       'Kansas', 'Montana', 'Virginia', 'California', 'Kentucky',\n       'South Carolina', 'Alaska', 'Indiana', 'New Jersey', 'Washington',\n       'Colorado', 'New York'], dtype=object)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Alright, the heavy states all there. Nothing to worry about using that weighting system"},{"metadata":{},"cell_type":"markdown","source":"Now to our invented strategy which picks the best pollster"},{"metadata":{"trusted":true},"cell_type":"code","source":"# a slightly modified date weighting function to work on non-vectors of date\ndef w_date1(date):\n    return 1 - (end_p - date).days/ d_date\n\ndef Assimilate3(state): \n# returns assimilated probability\n    Sample_size = 0 # to total sample size \n    W = 0 # to total the weights\n    PB = 0 # to total weight^T*perc for Biden\n    PT = 0\n    for date in period:\n        for grade in range(13):\n            # check if the state and date have a pollster with quality=grade\n            if state in data_period[data_period['fte_grade'] == grade].state.unique():\n                    if date in data_period[data_period['fte_grade'] == grade].end_date.unique():\n                        Best = data_period[data_period['fte_grade'] == grade]\n                        Best = Best[Best['state'] == state]\n                        Best = Best[Best['end_date'] == date] # subtable at date, state, best available grade\n                        pB = Best[Best['answer'] == 'Biden']['pct'] # vector of Biden percentages\n                        pT = Best[Best['answer'] == 'Trump']['pct'] # vector of Trump percentages\n                        Sz = Best[Best['answer'] == 'Biden']['sample_size'] # corresponding sample sizes\n\n                        SZ = np.sum(Sz)\n                        Sample_size += SZ\n                        W += w_date1(date)*SZ # we use both sample size and date to set a weight\n                        PB += w_date1(date)*0.01*np.dot(Sz,pB)\n                        PT += w_date1(date)*0.01*np.dot(Sz,pT)\n                        break\n    return Sample_size, PB/W, PT/W","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Assimilate3('Florida')","execution_count":95,"outputs":[{"output_type":"execute_result","execution_count":95,"data":{"text/plain":"(26698.0, 0.48882099810265045, 0.4658498926833317)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Sample size is still huge"},{"metadata":{},"cell_type":"markdown","source":"Let's consider maximum 3 weeks ahead of the last available date"},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import timedelta","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# a slightly modified date weighting function to suit more the short time period\ndef w_date2(date):\n    return 1 - (end_p - date).days/ 7\n\ndelta = timedelta(days = 3)\ndef Assimilate4(state): \n# returns assimilated probability\n    Sample_size = 0 # to total sample size \n    W = 0 # to total the weights\n    PB = 0 # to total weight^T*perc for Biden\n    PT = 0\n    for dd in period:\n        if state in data_period[data_period['end_date'] == dd].state.unique():\n            for date in pd.date_range(start=dd-delta, end=dd):\n                for grade in range(13):\n                    # check if the state and date have a pollster with quality=grade\n                    if state in data_period[data_period['fte_grade'] == grade].state.unique():\n                            if date in data_period[data_period['fte_grade'] == grade].end_date.unique():\n                                Best = data_period[data_period['fte_grade'] == grade]\n                                Best = Best[Best['state'] == state]\n                                Best = Best[Best['end_date'] == date] # subtable at date, state, best available grade\n                                pB = Best[Best['answer'] == 'Biden']['pct'] # vector of Biden percentages\n                                pT = Best[Best['answer'] == 'Trump']['pct'] # vector of Trump percentages\n                                Sz = Best[Best['answer'] == 'Biden']['sample_size'] # corresponding sample sizes\n\n                                SZ = np.sum(Sz)\n                                Sample_size += SZ\n                                W += w_date2(date)*SZ # we use both sample size and date to set a weight\n                                PB += w_date2(date)*0.01*np.dot(Sz,pB)\n                                PT += w_date2(date)*0.01*np.dot(Sz,pT)\n                                break\n                break\n    return Sample_size, PB/W, PT/W","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Assimilate4('Florida')","execution_count":117,"outputs":[{"output_type":"execute_result","execution_count":117,"data":{"text/plain":"(9720.0, 0.49416968715648124, 0.4519308357348704)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Let's re-define our bootstrapping fn to implement Assimilate4"},{"metadata":{"trusted":true},"cell_type":"code","source":"def Return_prob_Biden1(num_sim, state):\n    #num_sim is number of scenarios\n    #percs is the vector of probabilities 0: p_Biden 0, 1: p_Trump, 2:p_Other based on the assimilated percentages\n    sample_size,p0,p1 = Assimilate4(state)\n    sz = int(sample_size)\n    sim_polls = np.random.choice([0,1,2], (num_sim, sz),[p0,p1,1-p0-p1])\n    return np.mean(np.sum(sim_polls == np.zeros((num_sim, sz)),axis = 1)> \n                   np.sum(sim_polls == np.ones((num_sim, sz)),axis = 1))","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%timeit\nReturn_prob_Biden1(50000, 'Florida')","execution_count":128,"outputs":[{"output_type":"stream","text":"14.8 s ± 2.8 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Now we assimilate only based on the most recent date available, and best grade available for that date"},{"metadata":{"trusted":true},"cell_type":"code","source":"def Assimilate5(state): \n    date = data_period[data_period['state'] == state].end_date.max() # last date for the state\n    stata = data_period[data_period['state'] == state]\n    grade = stata[stata['end_date'] == date].fte_grade.min() # best grade available\n    stata = stata[stata['fte_grade'] == grade]\n    stataB = stata[stata['answer']=='Biden']\n    stataT = stata[stata['answer']=='Trump']\n    sz = stataB.sample_size\n    szz = np.sum(sz)\n    pB = 0.01*stataB.pct\n    pT = 0.01*stataT.pct\n    return szz, np.dot(pB,sz)/szz, np.dot(pT,sz)/szz","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Assimilate5('Florida')","execution_count":148,"outputs":[{"output_type":"execute_result","execution_count":148,"data":{"text/plain":"(9264.0, 0.49012629533678764, 0.46509067357512957)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Return_prob_Biden2(num_sim, state):\n    #num_sim is number of scenarios\n    #percs is the vector of probabilities 0: p_Biden 0, 1: p_Trump, 2:p_Other based on the assimilated percentages\n    sample_size,p0,p1 = Assimilate5(state)\n    sz = int(sample_size)\n    sim_polls = np.random.choice([0,1,2], (num_sim, sz),[p0,p1,1-p0-p1])\n    return np.mean(np.sum(sim_polls == np.zeros((num_sim, sz)),axis = 1)> \n                   np.sum(sim_polls == np.ones((num_sim, sz)),axis = 1))","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Return_prob_Biden2(10000, 'Florida')","execution_count":153,"outputs":[{"output_type":"execute_result","execution_count":153,"data":{"text/plain":"0.497"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Now we are able to creat a vector of probabilities for all states for every candiadate. We record only Biden vs Trump, and lump the rest as Other."},{"metadata":{"trusted":true},"cell_type":"code","source":"for state in data_period['state'].unique():\n    print(state, Return_prob_Biden2(10000, state))","execution_count":null,"outputs":[{"output_type":"stream","text":"Iowa 0.4945\nPennsylvania 0.5049\nFlorida 0.4906\nNebraska CD-2 0.4852\nMontana 0.4873\nMaine 0.4903\nMaine CD-2 0.4954\nMaine CD-1 0.4958\nArizona 0.4944\n","name":"stdout"}]},{"metadata":{},"cell_type":"raw","source":"Beauty! ... Nope, it crashed after Arizona (9th)"},{"metadata":{},"cell_type":"markdown","source":"Thinking of doing it 5 states at a time"},{"metadata":{"trusted":true},"cell_type":"code","source":"SS = data_period['state'].unique()","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for s in range(5):\n    print(SS[s], Return_prob_Biden2(10000, SS[s]))","execution_count":38,"outputs":[{"output_type":"stream","text":"Iowa 0.4965\nPennsylvania 0.4991\nFlorida 0.4985\nNebraska CD-2 0.493\nMontana 0.4862\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for s in range(5,10):\n    print(SS[s], Return_prob_Biden2(10000, SS[s]))","execution_count":null,"outputs":[{"output_type":"stream","text":"Maine 0.4877\nMaine CD-2 0.4844\nMaine CD-1 0.4931\nArizona 0.4859\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Crashed again. Ok, let's do 5000 simulations"},{"metadata":{"trusted":true},"cell_type":"code","source":"for state in data_period['state'].unique():\n    print(state, Return_prob_Biden2(5000, state))","execution_count":null,"outputs":[{"output_type":"stream","text":"Iowa 0.494\nPennsylvania 0.4862\nFlorida 0.4892\nNebraska CD-2 0.4884\nMontana 0.4974\nMaine 0.4888\nMaine CD-2 0.4864\nMaine CD-1 0.477\nArizona 0.5012\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}